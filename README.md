# awesome-online-courses [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

A repository of inspiring machine learning papers.

## Recommendation
| Paper | Authors | Code | Notes |
| --- | --- | --- | --- |
|How Airbnb Tells You Will Enjoy Sunset Sailing in Barcelona? Recommendation in a Two-Sided Travel Marketplace|Liang Wu, Mihajlo Grobovic | | The paper presents Airbnb's efforts on building recommender system for two-sided maretplace. In particular, it expands the knowlege graph with location-specific concepts and utilize location features with global-local mode. |

## Graphs
| Paper | Authors | Code | Notes |
| --- | --- | --- | --- |
|[When Does Self-Supervision Help Graph Convolutional Networks?](https://arxiv.org/abs/2006.09136)|Yuning You, Tianlong Chen, Zhangyang Wang, Yang Shen|[Python](https://github.com/Shen-Lab/SS-GCNs)| This paper explores three schemas of incorporating self-supervision into GCNs: pretraining+finetuning, self-training, multi-task learning, and designs three self-supervision tasks on graph: node clustering, graph partitioning, and graph completion.|

## Anomaly Detection
| Paper | Authors | Code | Notes |
| --- | --- | --- | --- |
|[Learning Confidence for Out-of-Distribution Detection in Neural Networks](https://arxiv.org/abs/1802.04865)|Terrance DeVries, Graham W. Taylor| [python](https://github.com/uoguelph-mlrg/confidence_estimation) | This paper proposes a method of estimating confidence for neural networks for out-of-distribution detection. A few important details: budget parameter, combating excessive regularization, and retraining misclassified examples, for the architecture to work well.|

## System
| Paper | Authors | Code | Notes |
| --- | --- | --- | --- |
|[fastai: A Layered API for Deep Learning](https://arxiv.org/abs/2002.04688)|Jeremy Howard, Sylvain Gugger|[Github](https://github.com/fastai/fastai) | The paper documents the philosophy behind the API design of the popular DL library fast.ai, which provides low, mid, and high level APIs, offering productivity as well as flexibility |

## Uncategorized for now
| Paper | Authors | Code | Notes |
| --- | --- | --- | --- |
|Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks|Shiyu Liang, Yixuan Li, R. Srikant| | |
|Beyond Sparsity: Tree Regularization of Deep Models for Interpretability| Mike Wu, Michael C. Hughes, Sonali Parbhoo, Maurizio Zazzi, Volker Roth, Finale Doshi-Velez| | |
|Robust Spammer Detection by Nash Reinforcement Learning| | | |
|Octet: Online Catalog Taxonomy Enrichment with Self-Supervision| | | |
|DeepAR: Probabilistic Forecasting with Autoregressive Recurrent Networks| David Slinas, Valentin Flunkert, Jan Gasthaus| | |Accelerating Large-Scale Inference with Anisotropic Vector Quantization| | | [Google Blog](https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html)|
|Auto-Keras: An Efficient Neural Architecture Search System| | | |
|When Do GNNs Work: Understanding and Improving Neighborhood Aggregation| | | |
|Continuous Graph Neural Networks| | | |
|TabNet: Attentive Interpretable Tabular Learning| | | |
|StarSpace:Embed All The Things| | | |
|CatBoost: gradient boosting with categorical features support| | | |
|Beyond User Embedding Matrix: Learning to Hash for Modeling Large-Scale Users in Recommendations
|On Calibration of Modern Neural Networks| | | |
|Deep Neural Networks as Gaussian Processes| | | |
|Learning and Transferring IDs Representation in E-commerce| | | |
|AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data| | | |
|Training with Multi-Layer Embeddings for Model Reduction| | | |
|Deep Learning Recommendation Model for Personalization and Recommendation Systems| | | |
|On the Bottleneck of Graph Neural Networks and its Practical Implications| | | |
|Neural Collaborative Filtering vs. Matrix Factorization Revisited| | | |
|Neural Machine Translation of Rare Words with Subword Units| | | |
|Debiasing Grid-based Product Search in E-commerce| | | |
